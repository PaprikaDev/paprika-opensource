{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceefa559-cf67-4cbb-970d-84661c36c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "env = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f7bb8f8-33b5-404b-984a-77e515536ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from IPython.display import Image\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c130533c-6cd0-414d-ad28-623e4ab6735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Dict, Any\n",
    "import operator\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "    output: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f48d37-3a4f-4ecd-9002-e4a8d16b8159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search_tool = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3923a2-c5d3-4384-9d74-f98813334c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download PDF tool\n",
    "from langchain.tools import tool\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from urllib.request import urlopen\n",
    "\n",
    "class SearchInput(BaseModel):\n",
    "    download_url: str = Field(description=\"the URL of the menu pdf\")\n",
    "    name: str = Field(description=\"the name of the restaurants\")\n",
    "\n",
    "@tool(\"download-pdf\", args_schema=SearchInput, return_direct=True)\n",
    "def download_pdf(download_url: str, filename: str):\n",
    "    \"\"\"Download a pdf file from a given url and filename\"\"\"\n",
    "    response = urlopen(download_url)\n",
    "    file = open(\"pdf/\"+filename+\".pdf\", 'wb')\n",
    "    file.write(response.read())\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b4ee54d-15aa-466b-85ca-eab668d1f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_tool, download_pdf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "52c371a8-5303-47dd-9e1e-3c40b003a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "118d3bfc-b16e-43d5-85ff-1a117b0e77a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.create_index(\n",
    "    name=\"quickstart\",\n",
    "    dimension=5120, # Lamma 2 embedding dim\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc4005b8-599b-4a87-8a68-5182b5d93bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    # Define the model\n",
    "    def __init__(self, model, tools, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_node(\"output-parser\", self.classify)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\",\n",
    "            self.exists_action,\n",
    "            {True: \"action\", False: \"output-parser\"}\n",
    "        )\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.add_edge(\"output-parser\", END)\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile()\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    # Check if llm requires action \n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "    # Run a tool ordered by the model\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}\n",
    "    # Perform inference on the gathered context\n",
    "    def classify(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    # def parse_output_to_string(self, state: AgentState):\n",
    "    #     message = state['messages'][-1]\n",
    "    #     json_output = JsonOutputParser(pydantic_object=Restaurants).invoke(message)\n",
    "    #     return {'json_output': json_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45d25c34-d883-43f6-a969-a02ffa03e645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are an AI tasked with finding and downloading a PDF of the menu for CRISP Rochester.\\nDO NOT respond as an AI assistant, only name and save the menu as a pdf after it's been found. \\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "\"\"\"You are an AI tasked with finding and downloading a PDF of the menu for {restaurant}.\n",
    "DO NOT respond as an AI assistant, only name and save the menu as a pdf after it's been found. \n",
    "\"\"\")\n",
    "\n",
    "prompt.format(restaurant=\"CRISP Rochester\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5afb42-f403-41d3-8a73-638ee6957c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "\"\"\"You are an AI tasked with classifying compatible diet types from a menu.\n",
    "\n",
    "----------\n",
    "{ menu }\n",
    "----------\n",
    "You output MUST be structured list of one or more of the provided diet types,\n",
    "{ diet_types }\n",
    "----------\n",
    "DO NOT respond as an AI assistant, only return a list of one or more diet types. \n",
    "If none fit, return an empty list.\n",
    "\n",
    "EXAMPLE:\n",
    "[\"diet_type_1\", \"diet_type_2\", ...]\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt.format(context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a1fe975-3bbc-4814-b979-048899d6d5df",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'invoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m llm \u001b[38;5;241m=\u001b[39m OllamaFunctions(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphi3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      3\u001b[0m     keep_alive\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, model, tools, system)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msystem \u001b[38;5;241m=\u001b[39m system\n\u001b[1;32m      5\u001b[0m graph \u001b[38;5;241m=\u001b[39m StateGraph(AgentState)\n\u001b[0;32m----> 6\u001b[0m graph\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m)\n\u001b[1;32m      7\u001b[0m graph\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m.\u001b[39mtake_action)\n\u001b[1;32m      8\u001b[0m graph\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput-parser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassify)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'invoke'"
     ]
    }
   ],
   "source": [
    "llm = OllamaFunctions(\n",
    "    model=\"phi3\", \n",
    "    keep_alive=-1,\n",
    "    format=\"json\"\n",
    ")\n",
    "\n",
    "model = Model(llm, tools, system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc51368-d3b3-4d0d-a5a4-5231db9eebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(model.graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ad031-e7ff-410f-baf1-bf70c1d7cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = [HumanMessage(content=\"CRISP Rochester\")]\n",
    "result = model.graph.invoke({\"restaurant\": input})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ragu",
   "language": "python",
   "name": "ragu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
