{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceefa559-cf67-4cbb-970d-84661c36c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f7bb8f8-33b5-404b-984a-77e515536ecb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_experimental'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnyMessage, SystemMessage, HumanMessage, ToolMessage\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JsonOutputParser\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_experimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mollama_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OllamaFunctions\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_experimental'"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from IPython.display import Image\n",
    "import IPython\n",
    "\n",
    "from typing import TypedDict, Annotated, Dict, Any\n",
    "import operator\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c130533c-6cd0-414d-ad28-623e4ab6735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    restaurant: str\n",
    "    output: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f48d37-3a4f-4ecd-9002-e4a8d16b8159",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This will be updated to a web-crawler to scrape menu's from a given restaurant\n",
    "\"\"\"\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "import requests\n",
    "\n",
    "search_url = \"https://s.jina.ai/\"\n",
    "read_url = \"https://r.jina.ai/\"\n",
    "\n",
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"should be a search query\")\n",
    "\n",
    "class ReadInput(BaseModel):\n",
    "    url: str = Field(description=\"should be a website URL\")\n",
    "\n",
    "@tool(\"search-tool\", args_schema=SearchInput, return_direct=True)\n",
    "def search_tool(query: str) -> str:\n",
    "    \"\"\"Search a query online and output the markdown, this is an expensive operation use only when needed\"\"\"\n",
    "    return requests.get(search_url + query)\n",
    "\n",
    "@tool(\"read-tool\", args_schema=ReadInput, return_direct=True)\n",
    "def read_tool(url: str) -> str:\n",
    "    \"\"\"Return markdown of given URL, less computationally expensive than the search tool\"\"\"\n",
    "    return requests.get(read_url + url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4ee54d-15aa-466b-85ca-eab668d1f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_tool, read_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4005b8-599b-4a87-8a68-5182b5d93bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    def __init__(self, model, tools, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_node(\"output-parser\", self.parse_output_to_string)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\",\n",
    "            self.exists_action,\n",
    "            {True: \"action\", False: \"output-parser\"}\n",
    "        )\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.add_edge(\"output-parser\", END)\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile()\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def parse_output_to_string(self, state: AgentState):\n",
    "        message = state['messages'][-1]\n",
    "        json_output = JsonOutputParser(pydantic_object=Restaurants).invoke(message)\n",
    "        return {'json_output': json_output}\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5afb42-f403-41d3-8a73-638ee6957c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "\"\"\"You are an AI tasked with classifying compatible diet types from a menu.\n",
    "\n",
    "----------\n",
    "{ menu }\n",
    "----------\n",
    "You output MUST be structured list of one or more of the provided diet types,\n",
    "{ diet_types }\n",
    "----------\n",
    "DO NOT respond as an AI assistant, only return a list of compatible diet types. You may return no diet types if no fit, or one\n",
    "\n",
    "EXAMPLE:\n",
    "[\"diet_type_1\", \"diet_type_2\", ...]\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt.format(context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1fe975-3bbc-4814-b979-048899d6d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaFunctions(\n",
    "    model=\"phi3\", \n",
    "    keep_alive=-1,\n",
    "    format=\"json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = Model(llm, tools, system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc51368-d3b3-4d0d-a5a4-5231db9eebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(abot.graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ad031-e7ff-410f-baf1-bf70c1d7cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = [HumanMessage(content=\"CRISP Rochester\")]\n",
    "result = abot.graph.invoke({\"restaurant\": input})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ragu",
   "language": "python",
   "name": "ragu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
